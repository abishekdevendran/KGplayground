{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "chat = ChatGroq(temperature=0, model_name=\"mixtral-8x7b-32768\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Low Latency Large Language Models (LLMs) are artificial intelligence models that can process and generate human-like text with a short response time. The importance of low latency in these models can be explained in the following ways:\\n\\n1. Improved User Experience: Low latency ensures that the model responds quickly to user inputs, providing a smooth and responsive user experience. Users are more likely to continue using and engage with a system that provides immediate feedback.\\n\\n2. Better Conversational Flow: When LLMs have low latency, conversations with users feel more natural and coherent. Quick responses allow the model to maintain context and build upon previous interactions, creating a more engaging and effective dialogue.\\n\\n3. Enhanced Real-time Applications: Applications requiring real-time language processing, such as live chatbots, customer support systems, or gaming AI, demand low latency for seamless integration and efficient performance.\\n\\n4. Increased Productivity: For businesses and organizations, low latency LLMs can improve productivity by reducing the time spent waiting for model responses. Faster processing allows for more interactions per unit of time, enabling higher throughput and better utilization of resources.\\n\\n5. Competitive Advantage: In many applications, low latency can provide a competitive advantage by offering a better user experience, improved real-time performance, and increased productivity. This can lead to higher customer satisfaction, better engagement, and potential revenue growth.\\n\\n6. Energy Efficiency: Lower latency can help reduce energy consumption and computational requirements. Faster processing allows for better management of resources, reducing the overall energy footprint of LLMs.\\n\\nIn summary, low latency is crucial for Large Language Models as it improves user experience, enhances real-time applications, increases productivity, provides a competitive advantage, and promotes energy efficiency.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = \"You are a helpful assistant.\"\n",
    "human = \"{text}\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system), (\"human\", human)])\n",
    "\n",
    "chain = prompt | chat\n",
    "chain.invoke({\"text\": \"Explain the importance of low latency LLMs.\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
