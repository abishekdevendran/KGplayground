{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.graphs import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=\"bolt://localhost:7687\",\n",
    "    username=\"neo4j\",\n",
    "    password=\"neo4j\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "llm = ChatOllama(model=\"mistral\", temperature=0)\n",
    "model= OllamaFunctions(model=\"mistral\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  4.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the documents\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "loader = DirectoryLoader('./input/', glob=\"**/*.txt\", use_multithreading=True, show_progress=True)\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the documents\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size=1000,\n",
    "  chunk_overlap=200,\n",
    "  length_function=len,\n",
    "  is_separator_regex=False\n",
    ")\n",
    "split_docs = splitter.split_documents(docs)\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup pydantic classes\n",
    "from langchain.graphs.graph_document import (\n",
    "    Node as BaseNode,\n",
    "    Relationship as BaseRelationship\n",
    ")\n",
    "from langchain.pydantic_v1 import Field, BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "class Property(BaseModel):\n",
    "  \"\"\"A single property consisting of key and value\"\"\"\n",
    "  key: str = Field(..., description=\"key\")\n",
    "  value: str = Field(..., description=\"value\")\n",
    "\n",
    "\n",
    "class Node(BaseNode):\n",
    "    properties: Optional[List[Property]] = Field(\n",
    "        None, description=\"List of node properties\")\n",
    "\n",
    "\n",
    "class Relationship(BaseRelationship):\n",
    "    properties: Optional[List[Property]] = Field(\n",
    "        None, description=\"List of relationship properties\"\n",
    "    )\n",
    "\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    \"\"\"Generate a knowledge graph with entities and relationships.\"\"\"\n",
    "    nodes: List[Node] = Field(..., description=\"List of nodes in the knowledge graph\")\n",
    "    rels: List[Relationship] = Field(..., description=\"List of relationships in the knowledge graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "def get_extraction_chain(\n",
    "    allowed_nodes: Optional[List[str]] = None,\n",
    "    allowed_rels: Optional[List[str]] = None\n",
    "    ):\n",
    "  sys_prompt = SystemMessage(content=f\"\"\"# Knowledge Graph Instructions for GPT-4\n",
    "  ## 1. Overview\n",
    "  You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\n",
    "  - **Nodes** represent entities and concepts. They're akin to Wikipedia nodes.\n",
    "  - The aim is to achieve simplicity and clarity in the knowledge graph, making it accessible for a vast audience.\n",
    "  ## 2. Labeling Nodes\n",
    "  - **Consistency**: Ensure you use basic or elementary types for node labels.\n",
    "    - For example, when you identify an entity representing a person, always label it as **\"person\"**. Avoid using more specific terms like \"mathematician\" or \"scientist\".\n",
    "  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\n",
    "  {'- **Allowed Node Labels:**' + \", \".join(allowed_nodes) if allowed_nodes else \"\"}\n",
    "  {'- **Allowed Relationship Types**:' + \", \".join(allowed_rels) if allowed_rels else \"\"}\n",
    "  ## 3. Handling Numerical Data and Dates\n",
    "  - Numerical data, like age or other related information, should be incorporated as attributes or properties of the respective nodes.\n",
    "  - **No Separate Nodes for Dates/Numbers**: Do not create separate nodes for dates or numerical values. Always attach them as attributes or properties of nodes.\n",
    "  - **Property Format**: Properties must be in a key-value format.\n",
    "  - **Quotation Marks**: Never use escaped single or double quotes within property values.\n",
    "  - **Naming Convention**: Use camelCase for property keys, e.g., `birthDate`.\n",
    "  ## 4. Coreference Resolution\n",
    "  - **Maintain Entity Consistency**: When extracting entities, it's vital to ensure consistency.\n",
    "  If an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"), \n",
    "  always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.  \n",
    "  Remember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial. \n",
    "  ## 5. Strict Compliance\n",
    "  Adhere to the rules strictly. Non-compliance will result in termination.\"\"\")\n",
    "\n",
    "  prompt = ChatPromptTemplate.from_messages([\n",
    "    sys_prompt,\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"Output format instructions: {format_instructions}\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"Use the given format to extract information from the following input: {input}\"),\n",
    "    HumanMessage(content=\"Tip: Make sure to answer in the correct format\"),\n",
    "  ])\n",
    "  from langchain.output_parsers import PydanticOutputParser\n",
    "  parser = PydanticOutputParser(pydantic_object=KnowledgeGraph)\n",
    "  partial_prompt = prompt.partial(\n",
    "      format_instructions=parser.get_format_instructions())\n",
    "  # use LCEL to pass the prompt to the model and force a structured response\n",
    "  extraction_chain = partial_prompt | llm | parser\n",
    "\n",
    "  return extraction_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.graphs.graph_document import GraphDocument\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "def format_property_key(s: str) -> str:\n",
    "    words = s.split()\n",
    "    if not words:\n",
    "        return s\n",
    "    first_word = words[0].lower()\n",
    "    capitalized_words = [word.capitalize() for word in words[1:]]\n",
    "    return \"\".join([first_word] + capitalized_words)\n",
    "\n",
    "def props_to_dict(props) -> dict:\n",
    "    \"\"\"Convert properties to a dictionary.\"\"\"\n",
    "    properties = {}\n",
    "    if not props:\n",
    "      return properties\n",
    "    for p in props:\n",
    "        properties[format_property_key(p.key)] = p.value\n",
    "    return properties\n",
    "\n",
    "def map_to_base_node(node: Node) -> BaseNode:\n",
    "    \"\"\"Map the KnowledgeGraph Node to the base Node.\"\"\"\n",
    "    properties = props_to_dict(node.properties) if node.properties else {}\n",
    "    # Add name property for better Cypher statement generation\n",
    "    properties[\"name\"] = node.id.title()\n",
    "    return BaseNode(\n",
    "        id=node.id.title(), type=node.type.capitalize(), properties=properties\n",
    "    )\n",
    "\n",
    "\n",
    "def map_to_base_relationship(rel: Relationship) -> BaseRelationship:\n",
    "    \"\"\"Map the KnowledgeGraph Relationship to the base Relationship.\"\"\"\n",
    "    source = map_to_base_node(rel.source)\n",
    "    target = map_to_base_node(rel.target)\n",
    "    properties = props_to_dict(rel.properties) if rel.properties else {}\n",
    "    return BaseRelationship(\n",
    "        source=source, target=target, type=rel.type, properties=properties\n",
    "    )\n",
    "\n",
    "def extract_and_store_graph(\n",
    "        document: Document,\n",
    "        nodes: Optional[List[str]] = None,\n",
    "        rels: Optional[List[str]] = None) -> None:\n",
    "    # Extract graph data using OpenAI functions\n",
    "    extract_chain = get_extraction_chain(nodes, rels)\n",
    "    data = extract_chain.invoke({\"input\": document.page_content})\n",
    "    # Construct a graph document\n",
    "    graph_document = GraphDocument(\n",
    "        nodes=[map_to_base_node(node) for node in data.nodes],\n",
    "        relationships=[map_to_base_relationship(rel) for rel in data.rels],\n",
    "        source=document\n",
    "    )\n",
    "    # Store information into a graph\n",
    "    graph.add_graph_documents([graph_document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, d in tqdm(enumerate(split_docs), total=len(split_docs)):\n",
    "    extract_and_store_graph(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
