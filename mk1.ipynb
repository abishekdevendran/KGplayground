{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.graphs import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=\"bolt://localhost:7687\",\n",
    "    username=\"neo4j\",\n",
    "    password=\"neo4j\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "# llm = ChatOllama(model=\"mistral\", temperature=0)\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "model= OllamaFunctions(model=\"mistral\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 43.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the documents\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "loader = DirectoryLoader('./input/', glob=\"**/*.txt\", use_multithreading=True, show_progress=True)\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the documents\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size=1000,\n",
    "  chunk_overlap=200,\n",
    "  length_function=len,\n",
    "  is_separator_regex=False\n",
    ")\n",
    "split_docs = splitter.split_documents(docs)\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup pydantic classes\n",
    "from langchain.graphs.graph_document import (\n",
    "    Node as BaseNode,\n",
    "    Relationship as BaseRelationship\n",
    ")\n",
    "from langchain.pydantic_v1 import Field, BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "class Property(BaseModel):\n",
    "  \"\"\"A single property consisting of key and value\"\"\"\n",
    "  key: str = Field(..., description=\"key\")\n",
    "  value: str = Field(..., description=\"value\")\n",
    "\n",
    "\n",
    "class Node(BaseNode):\n",
    "    properties: Optional[List[Property]] = Field(\n",
    "        None, description=\"List of node properties\")\n",
    "\n",
    "\n",
    "class Relationship(BaseRelationship):\n",
    "    properties: Optional[List[Property]] = Field(\n",
    "        None, description=\"List of relationship properties\"\n",
    "    )\n",
    "\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    \"\"\"Generate a knowledge graph with entities and relationships.\"\"\"\n",
    "    nodes: List[Node] = Field(..., description=\"List of nodes in the knowledge graph\")\n",
    "    rels: List[Relationship] = Field(..., description=\"List of relationships in the knowledge graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "def get_extraction_chain(\n",
    "    allowed_nodes: Optional[List[str]] = None,\n",
    "    allowed_rels: Optional[List[str]] = None\n",
    "    ):\n",
    "  sys_prompt = SystemMessage(content=f\"\"\"# Knowledge Graph Instructions for GPT-4\n",
    "  ## 1. Overview\n",
    "  You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\n",
    "  - **Nodes** represent entities and concepts. They're akin to Wikipedia nodes.\n",
    "  - The aim is to achieve simplicity and clarity in the knowledge graph, making it accessible for a vast audience.\n",
    "  ## 2. Labeling Nodes\n",
    "  - **Consistency**: Ensure you use basic or elementary types for node labels.\n",
    "    - For example, when you identify an entity representing a person, always label it as **\"person\"**. Avoid using more specific terms like \"mathematician\" or \"scientist\".\n",
    "  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\n",
    "  {'- **Allowed Node Labels:**' + \", \".join(allowed_nodes) if allowed_nodes else \"\"}\n",
    "  {'- **Allowed Relationship Types**:' + \", \".join(allowed_rels) if allowed_rels else \"\"}\n",
    "  ## 3. Handling Numerical Data and Dates\n",
    "  - Numerical data, like age or other related information, should be incorporated as attributes or properties of the respective nodes.\n",
    "  - **No Separate Nodes for Dates/Numbers**: Do not create separate nodes for dates or numerical values. Always attach them as attributes or properties of nodes.\n",
    "  - **Property Format**: Properties must be in a key-value format.\n",
    "  - **Quotation Marks**: Never use escaped single or double quotes within property values.\n",
    "  - **Naming Convention**: Use camelCase for property keys, e.g., `birthDate`.\n",
    "  ## 4. Coreference Resolution\n",
    "  - **Maintain Entity Consistency**: When extracting entities, it's vital to ensure consistency.\n",
    "  If an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"), \n",
    "  always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.  \n",
    "  Remember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial. \n",
    "  ## 5. Strict Compliance\n",
    "  Adhere to the rules strictly. Non-compliance will result in termination.\"\"\")\n",
    "\n",
    "  from langchain.output_parsers import PydanticOutputParser\n",
    "  parser = PydanticOutputParser(pydantic_object=KnowledgeGraph)\n",
    "\n",
    "  prompt = ChatPromptTemplate.from_messages([\n",
    "    sys_prompt,\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"{format_instructions}\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"Extract information from the following input and ONLY respond in the given format: {input}\"),\n",
    "    HumanMessage(content=\"Tip: Make sure to answer in the correct format\"),\n",
    "  ]).partial(format_instructions=parser.get_format_instructions())\n",
    "  \n",
    "  # use LCEL to pass the prompt to the model and force a structured response\n",
    "  extraction_chain = prompt | llm | parser\n",
    "\n",
    "  return extraction_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.graphs.graph_document import GraphDocument\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "def format_property_key(s: str) -> str:\n",
    "    words = s.split()\n",
    "    if not words:\n",
    "        return s\n",
    "    first_word = words[0].lower()\n",
    "    capitalized_words = [word.capitalize() for word in words[1:]]\n",
    "    return \"\".join([first_word] + capitalized_words)\n",
    "\n",
    "def props_to_dict(props) -> dict:\n",
    "    \"\"\"Convert properties to a dictionary.\"\"\"\n",
    "    properties = {}\n",
    "    if not props:\n",
    "      return properties\n",
    "    for p in props:\n",
    "        properties[format_property_key(p.key)] = p.value\n",
    "    return properties\n",
    "\n",
    "def map_to_base_node(node: Node) -> BaseNode:\n",
    "    \"\"\"Map the KnowledgeGraph Node to the base Node.\"\"\"\n",
    "    properties = props_to_dict(node.properties) if node.properties else {}\n",
    "    # Add name property for better Cypher statement generation\n",
    "    properties[\"name\"] = node.id.title()\n",
    "    return BaseNode(\n",
    "        id=node.id.title(), type=node.type.capitalize(), properties=properties\n",
    "    )\n",
    "\n",
    "\n",
    "def map_to_base_relationship(rel: Relationship) -> BaseRelationship:\n",
    "    \"\"\"Map the KnowledgeGraph Relationship to the base Relationship.\"\"\"\n",
    "    source = map_to_base_node(rel.source)\n",
    "    target = map_to_base_node(rel.target)\n",
    "    properties = props_to_dict(rel.properties) if rel.properties else {}\n",
    "    return BaseRelationship(\n",
    "        source=source, target=target, type=rel.type, properties=properties\n",
    "    )\n",
    "\n",
    "def extract_and_store_graph(\n",
    "        document: Document,\n",
    "        nodes: Optional[List[str]] = None,\n",
    "        rels: Optional[List[str]] = None) -> None:\n",
    "    # Extract graph data using OpenAI functions\n",
    "    extract_chain = get_extraction_chain(nodes, rels)\n",
    "    data = extract_chain.invoke({\"input\": document.page_content})\n",
    "    print(data)\n",
    "    # for chunk in extract_chain.stream({\"input\": document.page_content}):\n",
    "    #     print(chunk.content, end=\"\", flush=True)\n",
    "    # Construct a graph document\n",
    "    graph_document = GraphDocument(\n",
    "        nodes=[map_to_base_node(node) for node in data.nodes],\n",
    "        relationships=[map_to_base_relationship(rel) for rel in data.rels],\n",
    "        source=document\n",
    "    )\n",
    "    # Store information into a graph\n",
    "    graph.add_graph_documents([graph_document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clear the graph\n",
    "graph.query(\"MATCH (n) DETACH DELETE n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:19<03:31, 19.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes=[Node(id='Elon Musk', type='person', properties=[Property(key='name', value='Elon Musk')]), Node(id='Windows Laptop', type='product', properties=[Property(key='name', value='Windows Laptop')]), Node(id='Microsoft', type='company', properties=[Property(key='name', value='Microsoft')]), Node(id='X', type='socialMediaPlatform', properties=[Property(key='name', value='X')])] rels=[Relationship(source=Node(id='Elon Musk', type='person'), target=Node(id='Windows Laptop', type='product'), type='bought', properties=[]), Relationship(source=Node(id='Elon Musk', type='person'), target=Node(id='Microsoft', type='company'), type='tweetedAt', properties=[]), Relationship(source=Node(id='Elon Musk', type='person'), target=Node(id='X', type='socialMediaPlatform'), type='activeOn', properties=[])]\n",
      "nodes=[Node(id='Musk', type='person', properties=[Property(key='name', value='Musk')]), Node(id='Microsoft', type='organization', properties=[Property(key='name', value='Microsoft')]), Node(id='Microsoft account', type='product', properties=[Property(key='name', value='Microsoft account')]), Node(id='Community Notes', type='product', properties=[Property(key='name', value='Community Notes')]), Node(id='PC laptop', type='product', properties=[Property(key='name', value='PC laptop')])] rels=[Relationship(source=Node(id='Musk', type='person'), target=Node(id='PC laptop', type='product'), type='bought', properties=[]), Relationship(source=Node(id='Musk', type='person'), target=Node(id='Microsoft account', type='product'), type='refusedToCreate', properties=[]), Relationship(source=Node(id='Community Notes', type='product'), target=Node(id='Microsoft account', type='product'), type='mentioned', properties=[]), Relationship(source=Node(id='Musk', type='person'), target=Node(id='Community Notes', type='product'), type='criticized', properties=[])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [00:42<03:36, 21.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes=[Node(id='Community Notes', type='software', properties=[Property(key='status', value='failing')]), Node(id='Elon Musk', type='person', properties=[Property(key='profession', value='tech mogul')]), Node(id='Microsoft', type='company', properties=[Property(key='relationWithOpenAI', value='investor')]), Node(id='OpenAI', type='company', properties=[Property(key='origin', value='open source'), Property(key='currentStatus', value='closed source, maximum-profit company'), Property(key='control', value='Microsoft')]), Node(id='Google', type='company', properties=[])] rels=[Relationship(source=Node(id='Elon Musk', type='person'), target=Node(id='Community Notes', type='software'), type='commented', properties=[Property(key='comment', value='This option no longer exists')]), Relationship(source=Node(id='Elon Musk', type='person'), target=Node(id='Microsoft', type='company'), type='accused', properties=[Property(key='accusation', value='controlling OpenAI')]), Relationship(source=Node(id='Microsoft', type='company'), target=Node(id='OpenAI', type='company'), type='controls', properties=[]), Relationship(source=Node(id='OpenAI', type='company'), target=Node(id='Google', type='company'), type='counterweight', properties=[])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [01:14<02:14, 16.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes=[Node(id='Elon Musk', type='person', properties=[]), Node(id='OpenAI', type='company', properties=[])] rels=[Relationship(source=Node(id='Elon Musk', type='person'), target=Node(id='OpenAI', type='company'), type='founder', properties=[Property(key='endDate', value='2018')])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [01:34<02:05, 17.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes=[Node(id='Elon Musk', type='person', properties=[Property(key='role', value='CEO of Tesla and xAI')]), Node(id='Google', type='organization', properties=[Property(key='location', value='Mountain View, California')]), Node(id='Gemini AI chatbot', type='product', properties=[Property(key='feature', value='text-to-image generation'), Property(key='owner', value='Google')]), Node(id='X', type='platform', properties=[Property(key='previousName', value='Twitter')])] rels=[Relationship(source=Node(id='Elon Musk', type='person'), target=Node(id='Google', type='organization'), type='criticized', properties=[Property(key='reason', value='overplaying hand with AI image generation of Gemini'), Property(key='platform', value='X')]), Relationship(source=Node(id='Gemini AI chatbot', type='product'), target=Node(id='Google', type='organization'), type='ownedBy')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [02:04<02:11, 21.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes=[Node(id='Musk', type='person', properties=[Property(key='quote', value='I’m glad that Google overplayed their hand with their AI image generation, as it made their insane racist, anti-civilizational programming clear to all.')]), Node(id='Google', type='organization', properties=[Property(key='accusation', value='overplayed their hand with their AI image generation, insane racist, anti-civilizational programming')]), Node(id='Vivek Ramaswamy', type='person', properties=[Property(key='quote', value='The globally embarrassing rollout of Google’s LLM has proves that James Damore was 100% correct about Google’s descent into an ideological echo chamber. Employees working on Gemini surely realized it was a mistake to make it so blatantly racist, but they likely kept their mouths shut because they didn’t want to get fired like Damore. These companies program their employees with broken incentives, and those employees then program the AI with the same biases.'), Property(key='position', value='Republican leader')]), Node(id='James Damore', type='person', properties=[]), Node(id='Gemini', type='project', properties=[Property(key='associatedOrganization', value='Google')])] rels=[Relationship(source=Node(id='Musk', type='person'), target=Node(id='Google', type='organization'), type='criticizes', properties=[]), Relationship(source=Node(id='Vivek Ramaswamy', type='person'), target=Node(id='Google', type='organization'), type='criticizes', properties=[]), Relationship(source=Node(id='Vivek Ramaswamy', type='person'), target=Node(id='James Damore', type='person'), type='agreesWith', properties=[]), Relationship(source=Node(id='Gemini', type='project'), target=Node(id='Google', type='organization'), type='belongsTo', properties=[])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [02:18<01:37, 19.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes=[Node(id='Google', type='organization', properties=[Property(key='location', value='Mountain View, California')]), Node(id='Gemini', type='AI', properties=[Property(key='creator', value='Google'), Property(key='feature', value='image-generation'), Property(key='status', value='paused'), Property(key='issue', value='inaccuracies in some historical depictions')])] rels=[Relationship(source=Node(id='Google', type='organization'), target=Node(id='Gemini', type='AI'), type='created', properties=[]), Relationship(source=Node(id='Google', type='organization'), target=Node(id='Gemini', type='AI'), type='paused', properties=[Property(key='reason', value=\"address recent issues with Gemini's image generation feature\")])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [02:38<01:18, 19.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes=[Node(id='Google', type='organization', properties=[]), Node(id='Gemini', type='ai', properties=[Property(key='ownedBy', value='Google')]), Node(id='Elon Musk', type='person', properties=[Property(key='activity', value='tweeting memes')]), Node(id='Adolf Hitler', type='person', properties=[Property(key='activity', value='ordering the deaths of millions of people')]), Node(id='Nate Silver', type='person', properties=[Property(key='profession', value='Psephologist')])] rels=[Relationship(source=Node(id='Nate Silver', type='person'), target=Node(id='Google', type='organization'), type='criticizes', properties=[]), Relationship(source=Node(id='Gemini', type='ai'), target=Node(id='Elon Musk', type='person'), type='compares', properties=[]), Relationship(source=Node(id='Gemini', type='ai'), target=Node(id='Adolf Hitler', type='person'), type='compares', properties=[])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [03:11<01:11, 23.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes=[Node(id='Google DeepMind', type='organization', properties=[Property(key='location', value='New York, US'), Property(key='date', value='Dec. 8, 2023')]), Node(id=\"Alphabet's Google\", type='organization', properties=[Property(key='aiModel', value='Gemini'), Property(key='previousAiModel', value='PaLM 2'), Property(key='aiModelReleaseDate', value='May')]), Node(id='Gabby Jones', type='person', properties=[Property(key='profession', value='Photographer'), Property(key='affiliation', value='Bloomberg')]), Node(id='Silver', type='person', properties=[Property(key='previousPosition', value='head of data and polling news site FiveThirtyEight')]), Node(id='Elon', type='person', properties=[]), Node(id='Hitler', type='person', properties=[]), Node(id='Hindustan Times', type='organization', properties=[Property(key='description', value='your fastest source for breaking news')])] rels=[Relationship(source=Node(id=\"Alphabet's Google\", type='organization'), target=Node(id='Google DeepMind', type='organization'), type='owns', properties=[]), Relationship(source=Node(id=\"Alphabet's Google\", type='organization'), target=Node(id='Gemini', type='aiModel'), type='developed', properties=[]), Relationship(source=Node(id=\"Alphabet's Google\", type='organization'), target=Node(id='PaLM 2', type='aiModel'), type='developed', properties=[]), Relationship(source=Node(id='Gabby Jones', type='person'), target=Node(id='Bloomberg', type='organization'), type='worksFor', properties=[]), Relationship(source=Node(id='Silver', type='person'), target=Node(id='FiveThirtyEight', type='organization'), type='workedFor', properties=[])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [03:35<00:47, 23.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes=[Node(id='Hindustan Times', type='organization', properties=[Property(key='description', value='fastest source for breaking news')]), Node(id='Elon', type='person', properties=[Property(key='description', value='known for tweeting memes')]), Node(id='Hitler', type='person', properties=[Property(key='description', value='actions led to the deaths of millions of people')]), Node(id='Silver', type='person', properties=[Property(key='description', value='able to replicate this')]), Node(id='Gemini', type='product', properties=[Property(key='description', value='several months away from being ready for prime time'), Property(key='status', value='needs to be shut down'), Property(key='producer', value='Google')]), Node(id='Musk', type='person', properties=[Property(key='description', value='commented on the post')])] rels=[Relationship(source=Node(id='Silver', type='person'), target=Node(id='Gemini', type='product'), type='criticizes', properties=[]), Relationship(source=Node(id='Musk', type='person'), target=Node(id='Gemini', type='product'), type='comments', properties=[])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [04:09<00:27, 27.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes=[Node(id='Musk', type='person', properties=[Property(key='comment', value='It’s scary!')]), Node(id='Gemini', type='product', properties=[]), Node(id='Google', type='organization', properties=[Property(key='marketCap', value='$1.8 trillion')]), Node(id='Wuhan Institute of Virology', type='organization', properties=[Property(key='productRelease', value='SARS-CoV-2 in 2019')]), Node(id='SARS-CoV-2', type='product', properties=[]), Node(id='User1', type='person', properties=[Property(key='comment', value=\"It would be almost impossible to make a product less useful and more destructive than Google Gemini. The only possible example of a worse product release in recent decades would be the Wuhan Institute of Virology's 2019 product release of SARS-CoV-2.\")]), Node(id='User2', type='person', properties=[Property(key='comment', value='Google may work hard to lead in AI, but with this they have ensured that a large segment of the population will never trust or use their product')]), Node(id='User3', type='person', properties=[Property(key='comment', value=\"Correct. Google is self-immolating in front of the Internet. Google's market cap of $1.8 trillion is evaporating in real time.\")])] rels=[Relationship(source=Node(id='Musk', type='person'), target=Node(id='Gemini', type='product'), type='commented', properties=[]), Relationship(source=Node(id='User1', type='person'), target=Node(id='Gemini', type='product'), type='criticized', properties=[]), Relationship(source=Node(id='User2', type='person'), target=Node(id='Google', type='organization'), type='criticized', properties=[]), Relationship(source=Node(id='User3', type='person'), target=Node(id='Google', type='organization'), type='criticized', properties=[])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [04:24<00:24, 24.03s/it]\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Failed to parse KnowledgeGraph from completion {'nodes': [{'id': 'Gemini', 'type': 'concept', 'properties': []}, {'id': 'User1', 'type': 'person', 'properties': []}, {'id': 'User2', 'type': 'person', 'properties': []}, {'id': 'User3', 'type': 'person', 'properties': []}, {'id': 'SpeechIsViolence', 'type': 'concept', 'properties': []}, {'id': 'IndefensiblePosition', 'type': 'concept', 'properties': []}], 'rels': [{'source': 'User1', 'target': 'Gemini', 'type': 'criticizes', 'properties': []}, {'source': 'User2', 'target': 'SpeechIsViolence', 'type': 'believes', 'properties': []}, {'source': 'User2', 'target': 'IndefensiblePosition', 'type': 'holds', 'properties': []}, {'source': 'User3', 'target': 'Gemini', 'type': 'criticizes', 'properties': []}]}. Got: 8 validation errors for KnowledgeGraph\nrels -> 0 -> source\n  value is not a valid dict (type=type_error.dict)\nrels -> 0 -> target\n  value is not a valid dict (type=type_error.dict)\nrels -> 1 -> source\n  value is not a valid dict (type=type_error.dict)\nrels -> 1 -> target\n  value is not a valid dict (type=type_error.dict)\nrels -> 2 -> source\n  value is not a valid dict (type=type_error.dict)\nrels -> 2 -> target\n  value is not a valid dict (type=type_error.dict)\nrels -> 3 -> source\n  value is not a valid dict (type=type_error.dict)\nrels -> 3 -> target\n  value is not a valid dict (type=type_error.dict)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/sda1/GitHub/KGplayground/.venv/lib64/python3.12/site-packages/langchain_core/output_parsers/pydantic.py:23\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpydantic_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/mnt/sda1/GitHub/KGplayground/.venv/lib64/python3.12/site-packages/pydantic/v1/main.py:526\u001b[0m, in \u001b[0;36mBaseModel.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ValidationError([ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY)], \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sda1/GitHub/KGplayground/.venv/lib64/python3.12/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValidationError\u001b[0m: 8 validation errors for KnowledgeGraph\nrels -> 0 -> source\n  value is not a valid dict (type=type_error.dict)\nrels -> 0 -> target\n  value is not a valid dict (type=type_error.dict)\nrels -> 1 -> source\n  value is not a valid dict (type=type_error.dict)\nrels -> 1 -> target\n  value is not a valid dict (type=type_error.dict)\nrels -> 2 -> source\n  value is not a valid dict (type=type_error.dict)\nrels -> 2 -> target\n  value is not a valid dict (type=type_error.dict)\nrels -> 3 -> source\n  value is not a valid dict (type=type_error.dict)\nrels -> 3 -> target\n  value is not a valid dict (type=type_error.dict)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(split_docs), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(split_docs)):\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mextract_and_store_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[67], line 47\u001b[0m, in \u001b[0;36mextract_and_store_graph\u001b[0;34m(document, nodes, rels)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_and_store_graph\u001b[39m(\n\u001b[1;32m     42\u001b[0m         document: Document,\n\u001b[1;32m     43\u001b[0m         nodes: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m         rels: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Extract graph data using OpenAI functions\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     extract_chain \u001b[38;5;241m=\u001b[39m get_extraction_chain(nodes, rels)\n\u001b[0;32m---> 47\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mextract_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# for chunk in extract_chain.stream({\"input\": document.page_content}):\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m#     print(chunk.content, end=\"\", flush=True)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# Construct a graph document\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/sda1/GitHub/KGplayground/.venv/lib64/python3.12/site-packages/langchain_core/runnables/base.py:2056\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2054\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2055\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2056\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2058\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2059\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2060\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2064\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/mnt/sda1/GitHub/KGplayground/.venv/lib64/python3.12/site-packages/langchain_core/output_parsers/base.py:169\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage], config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    167\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    180\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    181\u001b[0m             config,\n\u001b[1;32m    182\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    183\u001b[0m         )\n",
      "File \u001b[0;32m/mnt/sda1/GitHub/KGplayground/.venv/lib64/python3.12/site-packages/langchain_core/runnables/base.py:1243\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1239\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1240\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[1;32m   1241\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1242\u001b[0m         Output,\n\u001b[0;32m-> 1243\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1246\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1247\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1251\u001b[0m     )\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1253\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/mnt/sda1/GitHub/KGplayground/.venv/lib64/python3.12/site-packages/langchain_core/runnables/config.py:326\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    325\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sda1/GitHub/KGplayground/.venv/lib64/python3.12/site-packages/langchain_core/output_parsers/base.py:170\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage], config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    167\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m--> 170\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    173\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    174\u001b[0m             config,\n\u001b[1;32m    175\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    176\u001b[0m         )\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    180\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    181\u001b[0m             config,\n\u001b[1;32m    182\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    183\u001b[0m         )\n",
      "File \u001b[0;32m/mnt/sda1/GitHub/KGplayground/.venv/lib64/python3.12/site-packages/langchain_core/output_parsers/pydantic.py:27\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     25\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpydantic_object\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m     26\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to parse \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from completion \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson_object\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output\u001b[38;5;241m=\u001b[39mjson_object)\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Failed to parse KnowledgeGraph from completion {'nodes': [{'id': 'Gemini', 'type': 'concept', 'properties': []}, {'id': 'User1', 'type': 'person', 'properties': []}, {'id': 'User2', 'type': 'person', 'properties': []}, {'id': 'User3', 'type': 'person', 'properties': []}, {'id': 'SpeechIsViolence', 'type': 'concept', 'properties': []}, {'id': 'IndefensiblePosition', 'type': 'concept', 'properties': []}], 'rels': [{'source': 'User1', 'target': 'Gemini', 'type': 'criticizes', 'properties': []}, {'source': 'User2', 'target': 'SpeechIsViolence', 'type': 'believes', 'properties': []}, {'source': 'User2', 'target': 'IndefensiblePosition', 'type': 'holds', 'properties': []}, {'source': 'User3', 'target': 'Gemini', 'type': 'criticizes', 'properties': []}]}. Got: 8 validation errors for KnowledgeGraph\nrels -> 0 -> source\n  value is not a valid dict (type=type_error.dict)\nrels -> 0 -> target\n  value is not a valid dict (type=type_error.dict)\nrels -> 1 -> source\n  value is not a valid dict (type=type_error.dict)\nrels -> 1 -> target\n  value is not a valid dict (type=type_error.dict)\nrels -> 2 -> source\n  value is not a valid dict (type=type_error.dict)\nrels -> 2 -> target\n  value is not a valid dict (type=type_error.dict)\nrels -> 3 -> source\n  value is not a valid dict (type=type_error.dict)\nrels -> 3 -> target\n  value is not a valid dict (type=type_error.dict)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, d in tqdm(enumerate(split_docs), total=len(split_docs)):\n",
    "    extract_and_store_graph(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
